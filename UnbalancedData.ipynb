{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unbalanced data classification techniques\n",
    "**Jan Chudy**  \n",
    "Overview of **techniques for unbalanced data classification** used to date and their comparison.\n",
    "\n",
    "The main objective of this notebook is to show and compare some of the techniques used for classification on unbalanced datasets. Most of these techniques are resampling strategies which are modifying the dataset in order to help our model classify the minority class (which is in most of the cases the most important one)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "References:  \n",
    "- [1] Porto Seguro’s Safe Driver Prediction on Kaggle: https://www.kaggle.com/c/porto-seguro-safe-driver-prediction\n",
    "- [2] T. Fawcett - Learning from Imbalanced Classes: https://www.svds.com/learning-imbalanced-classes/\n",
    "- [X] R. Alencar - Resampling strategies for imbalanced datasets: https://www.kaggle.com/rafjaa/resampling-strategies-for-imbalanced-datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing libraries\n",
    "\n",
    "Here are **all the libraries** we will need. Let's start with the basic ones:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # advanced math functionalities\n",
    "import pandas as pd # powerful data structures for data analysis\n",
    "import matplotlib.pyplot as plt # a numerical plotting library\n",
    "import seaborn as sns # library for plotting and styling\n",
    "\n",
    "# import warnings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configuring some options:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 60) # forces pandas to displat 60 columns at a time\n",
    "\n",
    "# configure seaborn to our liking\n",
    "sns.set_style('darkgrid', {\"axes.facecolor\": \".95\", \"axes.edgecolor\": \"black\", \\\n",
    "                           \"xtick.bottom\": \"True\", \"ytick.left\": \"True\"})\n",
    "sns.set_context(\"notebook\")\n",
    "sns.set_palette([\"#28abe3\", \"#db3340\", \"#e8b71a\", \"#1fda9a\", \"#f7eac8\"])\n",
    "blend_palette = sns.diverging_palette(258, 12, sep=20, as_cmap=True)\n",
    "\n",
    "# plots within notebook versus launching a separate window\n",
    "%matplotlib inline\n",
    "\n",
    "# warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And some specific libraries and utilities like models, metrics and other algorithms. We will import everything here, nevertheless, I will also add a commented import in every example as needed (in order for you to know which includes are needed for that specific example/model)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression # Logistic Regression classifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split # for splitting dataset into train and test portions\n",
    "from sklearn.metrics import accuracy_score # accuracy metric\n",
    "from sklearn.metrics import confusion_matrix # confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbalanced Data\n",
    "\n",
    "Unbalanced data (or class imbalance) typically refers to a machine learning classification problem where the classes do not make up equal portions of your dataset (Class A - 2%/Class B - 98% of the dataset). Having unbalanced data is very common in general and in practice, you can come across extremely unbalanced data.\n",
    "\n",
    "**Examples <sup>[2]</sup>:**\n",
    "- About 2% of credit card accounts are defrauded per year.\n",
    "- Medical screening for a condition is usually performed on a large population of people without the condition, to detect a small minority with it (e.g., HIV prevalence in the USA is ~0.4%).\n",
    "- Disk drive failures are approximately ~1% per year.\n",
    "- The conversion rates of online ads has been estimated to lie between 10<sup>-3</sup> to 10<sup>-6</sup>.\n",
    "- Factory production defect rates typically run about 0.1%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Dataset\n",
    "\n",
    "The dataset we are going to use for our testing is from the [Porto Seguro’s Safe Driver Prediction competition on Kaggle](https://www.kaggle.com/c/porto-seguro-safe-driver-prediction/). The objective of this dataset is to predict the probability that a driver files a claim in the next year (classification problem).\n",
    "\n",
    "**Data Description <sup>[1]</sup>:**\n",
    "In the train and test data, features that belong to similar groupings are tagged as such in the feature names (e.g., <code>ind</code>, <code>reg</code>, <code>car</code>, <code>calc</code>). In addition, feature names include the postfix <code>bin</code> to indicate binary features and <code>cat</code> to indicate categorical features. Features without these designations are either continuous or ordinal. Values of <code>-1</code> indicate that the feature was missing from the observation. The <code>target</code> columns signifies whether or not a claim was filed for that policy holder.\n",
    "\n",
    "We can load the dataset and take a peek at its columns and values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read data into pandas\n",
    "df = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>target</th>\n",
       "      <th>ps_ind_01</th>\n",
       "      <th>ps_ind_02_cat</th>\n",
       "      <th>ps_ind_03</th>\n",
       "      <th>ps_ind_04_cat</th>\n",
       "      <th>ps_ind_05_cat</th>\n",
       "      <th>ps_ind_06_bin</th>\n",
       "      <th>ps_ind_07_bin</th>\n",
       "      <th>ps_ind_08_bin</th>\n",
       "      <th>ps_ind_09_bin</th>\n",
       "      <th>ps_ind_10_bin</th>\n",
       "      <th>ps_ind_11_bin</th>\n",
       "      <th>ps_ind_12_bin</th>\n",
       "      <th>ps_ind_13_bin</th>\n",
       "      <th>ps_ind_14</th>\n",
       "      <th>ps_ind_15</th>\n",
       "      <th>ps_ind_16_bin</th>\n",
       "      <th>ps_ind_17_bin</th>\n",
       "      <th>ps_ind_18_bin</th>\n",
       "      <th>ps_reg_01</th>\n",
       "      <th>ps_reg_02</th>\n",
       "      <th>ps_reg_03</th>\n",
       "      <th>ps_car_01_cat</th>\n",
       "      <th>ps_car_02_cat</th>\n",
       "      <th>ps_car_03_cat</th>\n",
       "      <th>ps_car_04_cat</th>\n",
       "      <th>ps_car_05_cat</th>\n",
       "      <th>ps_car_06_cat</th>\n",
       "      <th>ps_car_07_cat</th>\n",
       "      <th>ps_car_08_cat</th>\n",
       "      <th>ps_car_09_cat</th>\n",
       "      <th>ps_car_10_cat</th>\n",
       "      <th>ps_car_11_cat</th>\n",
       "      <th>ps_car_11</th>\n",
       "      <th>ps_car_12</th>\n",
       "      <th>ps_car_13</th>\n",
       "      <th>ps_car_14</th>\n",
       "      <th>ps_car_15</th>\n",
       "      <th>ps_calc_01</th>\n",
       "      <th>ps_calc_02</th>\n",
       "      <th>ps_calc_03</th>\n",
       "      <th>ps_calc_04</th>\n",
       "      <th>ps_calc_05</th>\n",
       "      <th>ps_calc_06</th>\n",
       "      <th>ps_calc_07</th>\n",
       "      <th>ps_calc_08</th>\n",
       "      <th>ps_calc_09</th>\n",
       "      <th>ps_calc_10</th>\n",
       "      <th>ps_calc_11</th>\n",
       "      <th>ps_calc_12</th>\n",
       "      <th>ps_calc_13</th>\n",
       "      <th>ps_calc_14</th>\n",
       "      <th>ps_calc_15_bin</th>\n",
       "      <th>ps_calc_16_bin</th>\n",
       "      <th>ps_calc_17_bin</th>\n",
       "      <th>ps_calc_18_bin</th>\n",
       "      <th>ps_calc_19_bin</th>\n",
       "      <th>ps_calc_20_bin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.718070</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.883679</td>\n",
       "      <td>0.370810</td>\n",
       "      <td>3.605551</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.766078</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.618817</td>\n",
       "      <td>0.388716</td>\n",
       "      <td>2.449490</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.641586</td>\n",
       "      <td>0.347275</td>\n",
       "      <td>3.316625</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.580948</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>104</td>\n",
       "      <td>1</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>0.542949</td>\n",
       "      <td>0.294958</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.840759</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>82</td>\n",
       "      <td>3</td>\n",
       "      <td>0.316070</td>\n",
       "      <td>0.565832</td>\n",
       "      <td>0.365103</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  target  ps_ind_01  ps_ind_02_cat  ps_ind_03  ps_ind_04_cat  \\\n",
       "0   7       0          2              2          5              1   \n",
       "1   9       0          1              1          7              0   \n",
       "2  13       0          5              4          9              1   \n",
       "3  16       0          0              1          2              0   \n",
       "4  17       0          0              2          0              1   \n",
       "\n",
       "   ps_ind_05_cat  ps_ind_06_bin  ps_ind_07_bin  ps_ind_08_bin  ps_ind_09_bin  \\\n",
       "0              0              0              1              0              0   \n",
       "1              0              0              0              1              0   \n",
       "2              0              0              0              1              0   \n",
       "3              0              1              0              0              0   \n",
       "4              0              1              0              0              0   \n",
       "\n",
       "   ps_ind_10_bin  ps_ind_11_bin  ps_ind_12_bin  ps_ind_13_bin  ps_ind_14  \\\n",
       "0              0              0              0              0          0   \n",
       "1              0              0              0              0          0   \n",
       "2              0              0              0              0          0   \n",
       "3              0              0              0              0          0   \n",
       "4              0              0              0              0          0   \n",
       "\n",
       "   ps_ind_15  ps_ind_16_bin  ps_ind_17_bin  ps_ind_18_bin  ps_reg_01  \\\n",
       "0         11              0              1              0        0.7   \n",
       "1          3              0              0              1        0.8   \n",
       "2         12              1              0              0        0.0   \n",
       "3          8              1              0              0        0.9   \n",
       "4          9              1              0              0        0.7   \n",
       "\n",
       "   ps_reg_02  ps_reg_03  ps_car_01_cat  ps_car_02_cat  ps_car_03_cat  \\\n",
       "0        0.2   0.718070             10              1             -1   \n",
       "1        0.4   0.766078             11              1             -1   \n",
       "2        0.0  -1.000000              7              1             -1   \n",
       "3        0.2   0.580948              7              1              0   \n",
       "4        0.6   0.840759             11              1             -1   \n",
       "\n",
       "   ps_car_04_cat  ps_car_05_cat  ps_car_06_cat  ps_car_07_cat  ps_car_08_cat  \\\n",
       "0              0              1              4              1              0   \n",
       "1              0             -1             11              1              1   \n",
       "2              0             -1             14              1              1   \n",
       "3              0              1             11              1              1   \n",
       "4              0             -1             14              1              1   \n",
       "\n",
       "   ps_car_09_cat  ps_car_10_cat  ps_car_11_cat  ps_car_11  ps_car_12  \\\n",
       "0              0              1             12          2   0.400000   \n",
       "1              2              1             19          3   0.316228   \n",
       "2              2              1             60          1   0.316228   \n",
       "3              3              1            104          1   0.374166   \n",
       "4              2              1             82          3   0.316070   \n",
       "\n",
       "   ps_car_13  ps_car_14  ps_car_15  ps_calc_01  ps_calc_02  ps_calc_03  \\\n",
       "0   0.883679   0.370810   3.605551         0.6         0.5         0.2   \n",
       "1   0.618817   0.388716   2.449490         0.3         0.1         0.3   \n",
       "2   0.641586   0.347275   3.316625         0.5         0.7         0.1   \n",
       "3   0.542949   0.294958   2.000000         0.6         0.9         0.1   \n",
       "4   0.565832   0.365103   2.000000         0.4         0.6         0.0   \n",
       "\n",
       "   ps_calc_04  ps_calc_05  ps_calc_06  ps_calc_07  ps_calc_08  ps_calc_09  \\\n",
       "0           3           1          10           1          10           1   \n",
       "1           2           1           9           5           8           1   \n",
       "2           2           2           9           1           8           2   \n",
       "3           2           4           7           1           8           4   \n",
       "4           2           2           6           3          10           2   \n",
       "\n",
       "   ps_calc_10  ps_calc_11  ps_calc_12  ps_calc_13  ps_calc_14  ps_calc_15_bin  \\\n",
       "0           5           9           1           5           8               0   \n",
       "1           7           3           1           1           9               0   \n",
       "2           7           4           2           7           7               0   \n",
       "3           2           2           2           4           9               0   \n",
       "4          12           3           1           1           3               0   \n",
       "\n",
       "   ps_calc_16_bin  ps_calc_17_bin  ps_calc_18_bin  ps_calc_19_bin  \\\n",
       "0               1               1               0               0   \n",
       "1               1               1               0               1   \n",
       "2               1               1               0               1   \n",
       "3               0               0               0               0   \n",
       "4               0               0               1               1   \n",
       "\n",
       "   ps_calc_20_bin  \n",
       "0               1  \n",
       "1               0  \n",
       "2               0  \n",
       "3               0  \n",
       "4               0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display first 5 rows of the dataset\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The thing we are interested in, however, is how unbalanced the dataset is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values:  [0 1]\n",
      "Class_0: 573518\n",
      "Class_1: 21694\n",
      "True target values (Class_1) takes 3.64% of the data.\n",
      "Proportion Class_0 to Class_1: 26.44 to 1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAacAAAEcCAYAAABj4nsuAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAGjBJREFUeJzt3X2YnXV95/H3YSIQnCkzhqBCcBKt+bqy0yqpK25FsAVLd2VdxSeUxG6XVdR2i12trg+gViyiUkRQsOgSg8VdfEDrrhfaa0tJfGg1BRvUfmEpM+RBJMBMmjEQMDn7x31PrsOQSeYMk3N+mXm/rmuunPP73Q/fczyeD7/7/t33aTSbTSRJKskh3S5AkqTJDCdJUnEMJ0lScQwnSVJxDCdJUnEMJ0lScQwnqYsi4p6IeGG36yhVRNwZES/odh3qvAXdLkBqV0SMtzw9AtgJ7Kqfvykzv9DBWg4HHgSOy8xNndrvXBQRXwRuy8wPTbRl5jO6WJK6yHDSQSczeyceR8QwcE5m/vVMthURCzLzl7NU2pwREYcAZObuDu2vpxP70cHDcNKcExG/CVwCBLAD+J/AOzLzly0jnbcAbwceAZ4VEf8euBRYDFwDnAhcnpnX1tt8E/DHdf/3gDdm5mbg5nq3GRFN4OzMvGEvNb0F+K/AscAw8LrM3NBG3T3AZcCrgUPrbbw6MzMiXgZ8pN72GPDRzLxsLzWcW69/B3AWsAk4NzNvrvu/D3wL+B3g14FfrUPqyvr9uA+4MDNX18tfBAzW9bwE+Cfg9zLzx3X/EPApYAi4G3hnZn6z7vsicC/wLOA36/rPBF4eEe8CvpmZr4qIe4BXZua6iFgIfAx4BdVI+Trg3Zn5SEScDlwOfA54G/Aw8CedHEVrdnnOSXPRI8AfAIuAk4AzgHMmLfNSYAXw3Ih4KlUQvI0qfLbUfQBExGuA8+rtPBm4Bbi27n7RxGKZ2TtFMK0E3kkVCL8CvBIYbbPulwInAM8ABoDXtWzjc8CqzOwDngOsnfKdqer9Ub2Pi4AbIuJXWvrPBlYBfcA9wPVAAk+t9/nndYhOOBNYDTwJ+BrwlYjoqf8j4H8DN1C9p+8Aro+IZZP29b56Xx8Bvgz8af0+vmovtX8A+DWqsFsBnAL8SUv/INAAjqF6H6+MiF50UHLkpDknM/++5emdEXE1cDLVCGDChZk5BnvC4weZ+Y36+ceoRlUTzgU+lJm31/0fAHZExJOBbdMo6Rzgw5l5y0SJM6j7Eapgexbww4nRSW0XcHxE/DQz7wfu30ctGzPzU/Xjz0fE26lGStfXbVdnZtav85lUI6hTMnMn8MOIWA2sBL5TL//dzPx6vfxFVAF/AtAPNIFLMrMJ3BgR3wZeQxWKAF/KzL+rH++MiH2UDcDrgZWZeV+9vw9RhdqFdf8O4M/qQ5FfrUeyvwrcur8NqzyGk+aciHg28HGqL8mFVJ/z70xabGPL42Nan2fm7ojY3NI/SPVf4Ve0tP0SWML0wuk44M7HWfc3qYLpKuDYiPgS1WGrceBlwHuASyLiFqrDZz+YYjeTJ22MUL3+CZPfl62Z+eCk5X97b8vXhx+31Ov1A3fXwdS67rFT7GufIqIBPKXexlTb2zrpHNkOwJHTQcrDepqL/gL4B+AZmfkrwAepDve0av3S/BlV0AB7JgNM/hL9vczsb/lbmJnrJ21nKhupDsfNuO7MbGbmJZn5XKpDW78O/FHd973MfCnVIcdvAX+5j30smfT8aVSHMSe0vp4twOL6XE/r8q3BfdzEg/q82DH1elvqZSfvq3Xdye/dlO9lHXL3UP2HwlTb0xziyElzUR+wLTPHI+J44L8Ad+1j+a9TjTr+HdWX+3lU53UmXAm8NyJuqycgDAC/lZlfzsydEbENeDqPHZVMuBr4YD3h4B+BZwI79jL1fMq6I+JEqtHarcAvqE74746IJ1Kdm/o/wPb6b18z7I6rJ0ZcDbyWKly+NcWy/w/YAHwoIt4NHA+8gWqkNuHfRsRLgRupDoXeTxWwTwAOiYjzqCYqvJhq0kTr4dLJfk71Pk7lOuCCiPgR0EM1Wrx2H8vrIObISXPR24Bz6uuhrqCa7DClzPwZ1WSFy6hmpC2h+lLeWfdfR/UF+5WI+BeqgDitZRPnU53sH4uI/7CX7a+hmoX3Jarw+BLVYa926u6nmkU4Bvwz1SGtT9R9v18/30Y1mWHVPl7uzcBzgQeovtxfkZl7PTRZj1ZeBTybatQyMXtwXctiX673P0o1OeLMzNyVmQ9RTeJ4JVVgXQK8JjP/eR+1fQZ4Xv0+fnEv/ecDPwF+TPW/wXeAi/exPR3EGv7YoPRoEbGA6sv4jMz8XrfrmS31iOmVmXnqLG3vIuCozJw8E1J63DysJwER8bvAd6lGS++hOpm+vqtFSfOYh/Wkyouozu/cSzUb7eWZ+XB3S5Lmr44d1qsvyvtz4FTgIeB7mfnGiFhOdRHfIqpj06sy8456nY72SZLK0MmR08VUobQ8M4eorgyHaibUFZm5nOok8FUt63S6T5JUgI6MnOpbiGwCltQXDU60Hw3cDizKzF31dRL3U021bXSyLzO37u91NBqNw4DnUV0Xs2s/i0uSKj1Ut8D6QbPZ3DmdFTo1IeIZVCFwQUS8GBgH3kt1A87NmbkLoA6MLVTXXjQ63PeocIqIfiZN9z3iiCN+Y8eOHdcjSZqJk4B1+12KzoVTD9XFdbdk5jsi4vnAX1FdQ1Gq84ALWhuOPvpohoeHWbt2LUuWTL7QXpK0N5s2beKkk06C6qjTtHQqnO6murr9OoDM/LuIuI9q5HRsRPS0HGabuM9Zo8N9k11KddHjHtu2bVsCrO3v72fRokWz+f5I0pw1Pr7nbM60T4d0JJwy876I+Buqq+q/Vc+YmzjfdCvV1fnX1v/eMnH+JyI62jep5jGqq/H3aDQm355NknQgdPIi3HOBz0XEx6lu/78yM8fqq9ZXR8T5VLdAWTVpnU72SZIK4O2L2tBoNJYCd23YsIHBwcH9LC1JAhgZGWFoaAhgWbPZHJ7OOt4hQpJUHMNJklQcw0mSVBzDSZJUHH8yo8OecPgRHP6Enm6XocI89MguHnloR7fLkIphOHXY4U/o4ZQ1/kyQHu2mlSt45KFuVyGVw8N6kqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4izo1I4iYhh4qP4DeGdm3hgRJwJXAQuBYeDszLy3XqejfZKkMnR65PTKzHxO/XdjRBwCXAu8NTOXAzcDFwF0uk+SVI5uH9ZbATyUmevq51cCr+5SnySpEB07rFf7QkQ0gHXAu4GnASMTnZl5X0QcEhFP6nRfZj7QWmhE9AP9rW0DAwNLRkdHZ+FtkCTtSyfD6aTM3BgRhwGXApcDX+3g/tt1HnBBa0N/fz+jo6P09vbS19fXpbI0V/mZ0lzV29vb9jodC6fM3Fj/uzMiPgV8HfgEMDixTEQcBezOzAci4u5O9u2l5EuBa1obxsbGlgBrx8fH2b59+4zeB7+ANJWZfqak0o2Pj7e9TkfOOUXEEyPiyPpxA3gtcCuwHlgYES+sFz0XuL5+3Om+R8nMscwcbv0bHR3dNJPXL0lqT6cmRDwZuCki/hG4DVgOvCUzdwMrgU9HxB3AycC7ADrdJ0kqR6PZbHa7hoNGo9FYCty1YcMGBgcH97P03vX19XHKmvWzWZbmgJtWrvCwnuaskZERhoaGAJY1m83h6azT7ankkiQ9huEkSSqO4SRJKo7hJEkqjuEkSSqO4SRJKo7hJEkqjuEkSSqO4SRJKo7hJEkqjuEkSSqO4SRJKo7hJEkqjuEkSSqO4SRJKo7hJEkqjuEkSSqO4SRJKo7hJEkqjuEkSSqO4SRJKo7hJEkqjuEkSSqO4SRJKo7hJEkqjuEkSSqO4SRJKs6CTu8wIi4A3g8MZeZtEXEicBWwEBgGzs7Me+tlO9onSSpDR0dOEXECcCIwUj8/BLgWeGtmLgduBi7qRp8kqRwdC6eIOAy4AnhzS/MK4KHMXFc/vxJ4dZf6JEmF6OTI6YPAtZk53NL2NOpRFEBm3gccEhFP6kLfo0REf0Qsbf0bGBhY8rjeAUnStHTknFNEvAD4DeBdndjfLDkPuKC1ob+/n9HRUXp7e+nr6+tSWZqr/Exprurt7W17nU5NiDgZ+FfAXREBsAS4EbgMGJxYKCKOAnZn5gMRcXcn+/ZS86XANa0NY2NjS4C14+PjbN++fUZvhF9AmspMP1NS6cbHx9tepyOH9TLzosw8JjOXZuZSYBPwO8BHgYUR8cJ60XOB6+vH6zvcN7nmscwcbv0bHR3dNKM3QJLUlq5e55SZu4GVwKcj4g6qEda7utEnSSpHo9lsdruGg0aj0VgK3LVhwwYGBwf3s/Te9fX1ccqa9bNZluaAm1au8LCe5qyRkRGGhoYAljWbzeHprOMdIiRJxTGcJEnFMZwkScUxnCRJxTGcJEnFMZwkScUxnCRJxTGcJEnFMZwkScUxnCRJxTGcJEnFMZwkScUxnCRJxTGcJEnFMZwkScUxnCRJxZl2OEXE26do/+PZK0eSpPZGTudP0f7e2ShEkqQJC/a3QET8Vv2wJyJeDDRaup8O+NvSkqRZtd9wAj5b/3s48LmW9iZwD/CHs12UJGl+2284ZeYygIj4fGauOvAlSZLmu+mMnABoDaaIOGRS3+7ZLEqSNL9NO5wi4gTgCuDXqA7xQXX+qQn0zH5pkqT5atrhBKwG/gr4fWDHgSlHkqT2wmkQeE9mNg9UMZIkQXvXOX0VeMmBKkSSpAntjJwOB74aEeuoppDv4Sw+SdJsaiecflL/zUhE3AAsA3YD48AfZuatEbGc6nzWIuB+YFVm3lGv09E+SVIZ2plK/oHHua83ZOY2gIh4GdUFvScAVwJXZOa1EXE2cBUwcVeKTvdJkgrQzlTyKb/AM/P/7m/9iWCqHQnsjoijqQLqtLr9OuDyiFhMNU29Y32ZuXV/r0GS1BntHNb77KTni4FDgU1U99jbr4i4mmpSRQM4HTgO2JyZuwAyc1dEbKnbGx3ue1Q4RUQ/0N/aNjAwsGR0dHQ6L1WS9Di0c1hvWevziOihuiP5tG/8mpnn1OuuBD4KvG+663bBecAFrQ39/f2Mjo7S29tLX19fl8rSXOVnSnNVb29v2+u0M3J6lHrUcSHVyOmSNtddExGfqdc9NiJ66u31AMcAG6lGOZ3sm+xS4JrWhrGxsSXA2vHxcbZvn9nN2P0C0lRm+pmSSjc+Pt72OjMOp9ppVLPv9ikieoGBzNxYPz8DeAC4F7gVOAu4tv73lonzPxHR0b5WmTkGjLW2NRqNyYtJkg6AdiZEbKS6j96EI6iufXrLNFZ/InB9RDwR2EUVTGdkZjMizgVWR8T5wCjQes1Up/skSQVoNJvTuxtRRJw8qekXwO2Z+S+zXlWhGo3GUuCuDRs2MDg4OKNt9PX1ccqa9bNZluaAm1au8LCe5qyRkRGGhoYAljWbzeHprNPOhIi/hT0/l/Fk4Of+VIYk6UCY9r31IqIvIj4PPAhsBh6MiNURceQBq06SNC+1c+PXT1KdOxoCFtb/HgFcdgDqkiTNY+3M1jsdeHpmTvyW0+0R8Z+AO2e/LEnSfNbOyOkhqrtCtDoK2Dl75UiS1N7I6Wrg2xFxCTBC9eODbwP+4kAUJkmav9oJpwupJkK8nuquCluAizNz8j33JEl6XNo5rPcJIDPz1Mx8dmaeCvw0Ii49QLVJkuapdsLpLOCHk9rWA6+bvXIkSWovnJpAz6S2nja3IUnSfrUTLGuBP63vEDFxp4j31+2SJM2adiZE/BHwDeBnETECPA34GXDGgShMkjR/tXNvvU0RcQLwb6h+OXYj8PfeX0+SNNva+j2nOoi+X/9JknRAOJlBklQcw0mSVBzDSZJUHMNJklQcw0mSVBzDSZJUHMNJklQcw0mSVBzDSZJUHMNJklQcw0mSVBzDSZJUHMNJklSctu5KPlMRsQhYAzwDeBi4A3hTZm6NiBOBq4CFwDBwdmbeW6/X0T5JUhk6NXJqAhdnZmTmEHAncFH9a7rXAm/NzOXAzcBFsOeXdjvWJ0kqR0fCKTMfyMybWpq+DwwCK4CHMnNd3X4l8Or6caf7JEmF6Pg5p3r08mbg61Q/9T4y0ZeZ9wGHRMSTutA3uc7+iFja+jcwMLBkVt4ESdI+deSc0ySfBMaBy4GXd2H/03UecEFrQ39/P6Ojo/T29tLX19elsjRX+ZnSXNXb29v2Oh0Np4j4GPBM4IzM3B0Rd1Md3pvoPwrYnZkPdLpvL+VeClzT2jA2NrYEWDs+Ps727dtn9B74BaSpzPQzJZVufHy87XU6dlgvIj5Mdc7nP2bmzrp5PbAwIl5YPz8XuL5LfY+SmWOZOdz6Nzo6uqn9Vy5JaldHwikijgf+O3AM8N2IuDUivpqZu4GVwKcj4g7gZOBdAJ3ukySVo9FsNrtdw0Gj0WgsBe7asGEDg4OD+1l67/r6+jhlzfrZLEtzwE0rV3hYT3PWyMgIQ0NDAMuazebwdNbxDhGSpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIYTpKk4hhOkqTiGE6SpOIs6MROIuJjwJnAUmAoM2+r25cDq4FFwP3Aqsy8oxt9kqRydGrkdAPwImBkUvuVwBWZuRy4Ariqi32SpEJ0ZOSUmesAImJPW0QcDZwAnFY3XQdcHhGLgUYn+zJz6+SaI6If6G9tGxgYWDI6OjqTt0CS1IaOhNMUjgM2Z+YugMzcFRFb6vZGh/seE07AecAFrQ39/f2Mjo7S29tLX1/frL4Zkp8pzVW9vb1tr9PNcCrdpcA1rQ1jY2NLgLXj4+Ns3759Rhv1C0hTmelnSird+Ph42+t0M5w2AsdGRE89iukBjqnbGx3ue4zMHAPGWtsajcbsvwuSpMfo2lTyzLwXuBU4q246C7glM7d2uu/AvUpJ0kx0air5ZcArgKcAfx0R92fm8cC5wOqIOB8YBVa1rNbpPklSIRrNZrPbNRw0Go3GUuCuDRs2MDg4OKNt9PX1ccqa9bNZluaAm1au8JyT5qyRkRGGhoYAljWbzeHprOMdIiRJxTGcJEnFMZwkScUxnCRJxTGcJEnFMZwkScUxnCRJxTGcJEnFMZwkScUxnCRJxTGcJEnFMZwkScUxnCRJxTGcJEnFMZwkScUxnCRJxTGcJEnFMZwkScUxnCRJxTGcJEnFMZwkScUxnCRJxVnQ7QIklWPhoYey4LDDul2GCvPLnTt58OGHO7pPw0nSHgsOO4zv/e6Z3S5DhXnBN78MHQ4nD+tJkopjOEmSimM4SZKKMy/POUXEcmA1sAi4H1iVmXd0typJ0oT5OnK6ErgiM5cDVwBXdbkeSVKLeTdyioijgROA0+qm64DLI2JxZm5tWa4f6G9d98gjjxzctm0bmzdvnvH+e3t7eWjrlhmvr7lpeHgR4+Pj3S6D3t5efrbjF90uQ4UZHh5+XJ/Plu/MnumuM+/CCTgO2JyZuwAyc1dEbKnbt7Ysdx5wQeuKfX19bNu2jdNPP71jxWp+WPbful2BtA/Lls3Wlp4K3DmdBedjOE3XpcA1rQ2NRuPQQw899OkPP/zwHcCurlQ1RwwMDCzp7+9fOzY2dtLo6OimbtcjtfLzOet6qILpB9NdYT6G00bg2IjoqUdNPcAxdfsemTkGjO1l/ds7UOOcFxEALF68eNMDDzww3N1qpEfz83lATGvENGHeTYjIzHuBW4Gz6qazgFtazzdJkrprPo6cAM4FVkfE+cAosKrL9UiSWszLcMrMfwKe3+06JEl7N+8O66kYY8AH2Pt5Panb/Hx2WaPZbHa7BkmSHsWRkySpOIaTJKk483JChLrPm++qVBHxMeBMYCkwlJm3dbei+cmRk7rFm++qVDcALwJGul3IfGY4qeNabr57Xd10HXBCRCzuXlVSJTPXZebG/S+pA8lwUjc85ua7wMTNdyXJcJIklcdwUjfsufkuwFQ335U0fxlO6jhvvitpf7xDhLoiIp5FNZV8gPrmu5mZ3a1Kgoi4DHgF8BTgPuD+zDy+u1XNP4aTJKk4HtaTJBXHcJIkFcdwkiQVx3CSJBXHcJIkFcdwkiQVx3CSChARwxFxapf2fU1EfKgb+5amYjhJB7mJ20BJc4kX4UpdFhFrgNcDO4FdwAeB5wEnAQuBHwFvzswf18tfAzwIDAInAy8DbgGuqZ8ncCNwSma+sF7nWcAngRXAVuB9mfm/IuKNVL+n1QQeBv4mM8844C9a2g9HTlKXZeZK4G7gjMzszcyLgW8CzwSOBv4B+MKk1V4HXAj0AeuoAuYXVLfceUP9B0BEPBH4NvCX9fZeC3wqIp6dmZ+pt31xvW+DSUXwZ9qlAmXm5yYeR8T7gdGIODIzt9XNX8vM79T9j1D9rPi/zswdwE8iYjVwSr3sS4HhzPwf9fNbIuLLwKuADxzwFyPNgOEkFaY+h3QhVXgsBnbXXUcBE+HU+vMii6n+v9za1vp4EHh+RIy1tC0A1sxi2dKsMpykMrSe/H0d1XmkU4Fh4EiqO7c3plh+K/BLYAlwe93W+qvCG4G/zczTprFvqQiGk1SGnwNPrx/3UU2OuB84AvjwvlbMzF0R8RXg/RFxDvA0YBXVeSyAbwAXRcRK4It123OA8cz86aR9S0VwQoRUhj8D3lsfensSMAJsBn4CfH8a6/8B1QjrHqrDdddRBRyZuR14CdVEiC31Mh8BDqvX/Szw7IgYi4gbZusFSY+HU8mlOSgiPgI8JTPfsN+FpQJ5WE+aA+rrmA4FNlBdI/WfgXO6WpT0OBhO0tzQR3Uo7xiqc0gfB77W1Yqkx8HDepKk4jghQpJUHMNJklQcw0mSVBzDSZJUHMNJklQcw0mSVJz/D0h1Sh2BMG9iAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check uniqie values\n",
    "target = df.target\n",
    "print(\"Unique values: \", target.unique())\n",
    "\n",
    "# count rows with these values and compute proportion\n",
    "target_val_cnt = target.value_counts()\n",
    "print(\"Class_0:\", target_val_cnt[0])\n",
    "print(\"Class_1:\", target_val_cnt[1])\n",
    "print(\"True target values (Class_1) takes {:0.2f}% of the data.\".format(target_val_cnt[1]/len(target)*100))\n",
    "print(\"Proportion Class_0 to Class_1: {:0.2f} to 1\".format(target_val_cnt[0] / target_val_cnt[1]))\n",
    "\n",
    "# graphical representation of the proportion\n",
    "sns.barplot(x=target.unique(),y=target_val_cnt)\n",
    "plt.xlabel(\"target\")\n",
    "plt.ylabel(\"count\");\n",
    "plt.title(\"Target class proportion\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why is unbalanced data a problem\n",
    "\n",
    "With unbalanced dataset, machine learning algorithms are often biased towards the majority class. Loss functions of traditional algorithms attempt to optimize the accuracy, which is not taking the data distribution into consideration. In unbalanced datasets, accuracy is only reflecting the distribution of the majority class. This is also called the **Accuracy Paradox**. In the most extreme cases, minority target values might be treated as outliers of the majority class.\n",
    "\n",
    "What the model ends up doing in order to optimize the error rate is simply to predict the majority class for every instance (the more unbalanced the dataset). That will give us very high accuracy, which satisfies the model and is a completely correct solution. However, not for our problem, because (most likely) we are trying to correctly predict as much of the minority instances as possible (if a patient got a disease, we want to predict it).\n",
    "\n",
    "Therefore, accuracy is not the right metric to tell us how good is our model doing. A better metric for us to use would be **recall** (percent of positive instances that were classified as positive). However, there are more metrics for our consideration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try this on our dataset. We'll train a model and compute its accuracy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 96.36%\n"
     ]
    }
   ],
   "source": [
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.metrics import accuracy_score\n",
    "\n",
    "# drop target and id columns\n",
    "X = df[df.columns[2:]]\n",
    "\n",
    "# devide data into training and testing portion\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, target, test_size=0.2, random_state=1)\n",
    "\n",
    "# train the model and predict classes for testing portion\n",
    "LogReg = LogisticRegression(solver='liblinear')\n",
    "LogReg.fit(X_train, y_train)\n",
    "y_pred = LogReg.predict(X_test)\n",
    "\n",
    "# compute accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy: {:0.2f}%\".format(accuracy * 100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the trained model has very high accuracy. We could almost assume, that the model haven't even try to label any instance as a minority class. \n",
    "\n",
    "To find out how well our model really did, we would like to see how instances got misclassified (how many Class_1 targets and Class_0 targets did it miss). Of course, we could compute these values easily, but more interesting and helpful way to evaluate this is **Confusion matrix** (especially, when there are more than two target values)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# from sklearn.metrics import confusion_matrix \n",
    "\n",
    "# compute the Confusion matrix\n",
    "conf_mat = confusion_matrix(y_true=y_test, y_pred=y_pred)\n",
    "\n",
    "# plot a graphical representation of confusion matrix\n",
    "with sns.axes_style({'xtick.bottom': False, 'ytick.left': False}):\n",
    "    sns.heatmap(conf_mat, annot=True, fmt=\"d\", cmap=blend_palette)\n",
    "plt.xlabel('Predicted Class')\n",
    "plt.ylabel('Actual Class');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In other words, our model failed miserably solving our problem, because it hasn't classified a single Class_1 instance correctly. As we can see from the confusion matrix, it hasn't even tried to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How can we combat this problem?\n",
    "\n",
    "There are many approaches to this problem. Some of them are manipulating the data you have and some of them the algorithm you use. We will discuss these approaches and try out some of them. Here's an overview:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **Change performance metric**\n",
    "    - ROC curves & AUC\n",
    "    - F1 score\n",
    "    - Cohen’s kappa\n",
    "- **Cost function sensitivity**\n",
    "- **Resampling**\n",
    "    - **Trivial:**\n",
    "        - Getting more data\n",
    "        - Random Undersampling\n",
    "        - Random Oversampling\n",
    "    - **Advanced:**\n",
    "        - SMOTE\n",
    "        - ROSE\n",
    "        - Tomek Links\n",
    "    - **Specific:**\n",
    "        - EasyEnsemble\n",
    "        - BalanceCascade\n",
    "        - RUSBoost\n",
    "        - SMOTEBagging\n",
    "        - Underbagging\n",
    "        - Blagging (Balanced bagging)\n",
    "        - Box Drawings\n",
    "- **Different Perspective**\n",
    "    - Anomaly detection\n",
    "    - Change detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While dealing with unbalanced data, you will be trying to come up with the right combination (subset) of these approaches to solve your particular problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Change performance metric\n",
    "As we have shown earlier, accuracy is not the way to go in terms of model's performance evaluation. There are different performance metric for us to see (or tell our model) how well it is performing. Some of them are more comprehensive than others.\n",
    "\n",
    "We've already used the **Confusion matrix**, which is a very helpful way to see what was classified correctly and what was misclassified. It is also an important reference for some other performance metrics, so let's have a look what is the Confusion matrix showing us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Actual / Predicted |    Negative    |    Positive    |\n",
    "|:------------------:|:--------------:|:--------------:|\n",
    "|      **Negative**      |  True Negative | False Positive |\n",
    "|      **Positive**      | False Negative |  True Positive |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"font-size:0.8em\">Note: This concept is not limited for binary classification. Right now, we are assuming we have a Positive and a Negative class. You might find Confusion matrixes with a different order of rows/columns.</span>\n",
    "\n",
    "Just for completeness, **Accuracy** is the number all correctly classified instances divided by the total number of instances (<code>(TP + TN) / Total</code>). And we can already tell, why this is not suitable for us.\n",
    "\n",
    "Much better metrics (but still very basic) are the Recall and the Precision. We are usually trying to find the right balance between these two, and in most cases (when the minority class is more important to detect), we are more concerned about the recall.  \n",
    "The **recall** (also Sensitivity or True Positive Rate) is the number of True Positives divided by the number of all positive instances (<code>TP / (TP + FN)</code>). Low recall value indicates a high rate of False Negatives.  \n",
    "The **precision** (also Positive Predictive Value) is the number of True Positives divided by the number all positive predictions made by our model (<code>TP / (TP + FP)</code>).\n",
    "\n",
    "Let's have a look at some more advanced metrics which might be more helpful when dealing with unbalanced data.\n",
    "\n",
    "#### Area Under the ROC curve (AUC)\n",
    "[TODO]\n",
    "\n",
    "#### F1 Score\n",
    "[TODO]\n",
    "\n",
    "#### Cohen’s kappa\n",
    "[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cost function sensitivity\n",
    "Generally, an algorithm presumes, that misclassifying the majority class is identically bad as misclassifying the minority class (as we've demonstrated earlier). We should change the algorithm's perspective on our problem (especially when we are stuck with a specific algorithm we have to use).\n",
    "\n",
    "#### Penalization\n",
    "\n",
    "One way to do this is to **penalize our model** for misclassifying a minority class or reward it for classifying it correctly. Either way, our model will pay more attention to minority class instances. To be more precise, it will misclassify more majority instances (giving us more false positives), because it is less costly than misclassifying a minority class instance. This approach is also called **Cost-sensitive learning**.\n",
    "\n",
    "We can define our own **cost matrix**, which is used to calculate the cost and applied to the classifier (we define the cost of each classification of class A as class B). Setting the right penalization for your problem can be very complex.\n",
    "\n",
    "#### Adjusting class weights\n",
    "\n",
    "Adjusting the importance of the minority class is another way to penalize our model because it will directly affect the cost of its errors. In other words, we are balancing the data without changing the distribution of any class.\n",
    "\n",
    "Many classifiers from Scikit-learn takes an optional parameter <code>class_weight</code>, that can achieve this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[TODO]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Perspective\n",
    "[TODO]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
